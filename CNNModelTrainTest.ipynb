{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#Set hyperparameters\n",
    "ImageDir = r\"C:\\Users\\hgood\\OneDrive\\Processed_REMBRANDT\"\n",
    "CSVAcess = r\"C:\\Users\\hgood\\Downloads\\clinical_cleaned_v2.csv\"\n",
    "BatchSize = 32\n",
    "EpochCount = 10\n",
    "LearningRate = 0.001\n",
    "Classes = 3\n",
    "BestModelPathCNN = 'best_model.pth'\n",
    "\n",
    "# set dataset and class weights \n",
    "datasetREM = REMDataset(ImageDir, CSVAcess, transform=TransformImagesREM)\n",
    "REMlabels = [int(label) for _, label in datasetREM]\n",
    "Weights = compute_class_weight(class_weight='balanced', classes=np.unique(REMlabels), y=REMlabels)\n",
    "TensorWeights = torch.tensor(Weights, dtype=torch.float)\n",
    "\n",
    "# Split dataset into train/validation/testing\n",
    "TrainSplit = int(0.8 * len(datasetREM))\n",
    "ValSplit = int(0.1 * len(datasetREM))\n",
    "TestSplit = len(datasetREM) - TrainSplit - ValSplit\n",
    "TrainData, ValData, TestData = random_split(datasetREM, [TrainSplit, ValSplit, TestSplit])\n",
    "#Create data loaders three different ways.\n",
    "TrainingLoader = DataLoader(TrainData, batch_size=BatchSize, shuffle=True)\n",
    "ValidationLoader = DataLoader(ValData, batch_size=BatchSize, shuffle=False)\n",
    "TestingLoader = DataLoader(TestData, batch_size=BatchSize, shuffle=False)\n",
    "\n",
    "# Create model, loss, and optimizer, utilizing an Adam optimizer and learning rate scheduler as well.\n",
    "TorchDevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CNNModel = build_resnet(num_classes=Classes).to(TorchDevice)\n",
    "EntropyREM = nn.CrossEntropyLoss(weight=TensorWeights.to(TorchDevice))\n",
    "OptimizerREM = optim.Adam(CNNModel.parameters(), lr=LearningRate)\n",
    "SchedulerREM = optim.lr_scheduler.StepLR(OptimizerREM, step_size=5, gamma=0.1)\n",
    "\n",
    "# Resume training from checkpoint unless we start training from scratch\n",
    "start_epoch = 0\n",
    "best_val_accuracy = 0.0\n",
    "if os.path.exists(BestModelPathCNN):\n",
    "    checkpoint = torch.load(BestModelPathCNN)\n",
    "    CNNModel.load_state_dict(checkpoint['model_state_dict'])\n",
    "    OptimizerREM.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_accuracy = checkpoint['val_accuracy']\n",
    "    print(f\"Resuming training at epoch {start_epoch} with Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "\n",
    "TotalEpochs = start_epoch + EpochCount\n",
    "\n",
    "# Function to calculate accuracy and loss metrics.\n",
    "def evaluate_accuracy_metrics(loader):\n",
    "    CNNModel.eval()\n",
    "    CorrectPredictions = 0\n",
    "    TotalPredictions = 0\n",
    "    TotalLoss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, REMlabels in loader:\n",
    "            inputs, REMlabels = inputs.to(TorchDevice), REMlabels.to(TorchDevice)\n",
    "            outputs = CNNModel(inputs)\n",
    "            loss = EntropyREM(outputs, REMlabels)\n",
    "            TotalLoss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            CorrectPredictions += (predicted == REMlabels).sum().item()\n",
    "            TotalPredictions += REMlabels.size(0)\n",
    "    return TotalLoss / len(loader), 100 * CorrectPredictions/ TotalPredictions\n",
    "\n",
    "# Create the training loop.\n",
    "for epoch in range(start_epoch, TotalEpochs):\n",
    "    CNNModel.train()\n",
    "    TotalLoss = 0.0\n",
    "    CorrectPredictions = 0\n",
    "    TotalPredictions = 0\n",
    "# Reset gradients, pass outputs forward, calculate total loss, and utilize optimizer.\n",
    "    for inputs, REMlabels in TrainingLoader:\n",
    "        inputs, REMlabels = inputs.to(TorchDevice), REMlabels.to(TorchDevice)\n",
    "        OptimizerREM.zero_grad()\n",
    "        outputs = CNNModel(inputs)\n",
    "        loss = EntropyREM(outputs, REMlabels)\n",
    "        loss.backward()\n",
    "        OptimizerREM.step()\n",
    "        TotalLoss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        CorrectPredictions += (predicted == REMlabels).sum().item()\n",
    "        TotalPredictions += REMlabels.size(0)\n",
    "#Evaluate the model on both validation and test sets.\n",
    "    AvgTrainingLoss = TotalLoss/len(TrainingLoader)\n",
    "    TrainingAccuracy = 100 * CorrectPredictions/TotalPredictions\n",
    "    ValidationLoss, ValidationAccuracy = evaluate_accuracy_metrics(ValidationLoader)\n",
    "    TestingLoss, TestingAccuracy = evaluate_accuracy_metrics(TestingLoader)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{TotalEpochs}], Train Loss: {AvgTrainingLoss:.4f}, Train Accuracy: {TrainingAccuracy:.2f}%, \"\n",
    "          f\"Val Loss: {ValidationLoss:.4f}, Val Accuracy: {ValidationAccuracy:.2f}%, \"\n",
    "          f\"Test Loss: {TestingLoss:.4f}, Test Accuracy: {TestingAccuracy:.2f}%\")\n",
    "\n",
    "    SchedulerREM.step()\n",
    "# Save the latest checkpoint.\n",
    "    torch.save({\n",
    "        'model_state_dict': CNNModel.state_dict(),\n",
    "        'optimizer_state_dict': OptimizerREM.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, 'model_checkpoint.pth')\n",
    "\n",
    "# Save best model if the validation accuracy improves.\n",
    "    if ValidationAccuracy > best_val_accuracy:\n",
    "        best_val_accuracy = ValidationAccuracy\n",
    "        torch.save({\n",
    "            'model_state_dict': CNNModel.state_dict(),\n",
    "            'optimizer_state_dict': OptimizerREM.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'val_accuracy': ValidationAccuracy,\n",
    "            'test_accuracy': TestingAccuracy\n",
    "        }, BestModelPathCNN)\n",
    "        print(f\"Best model saved at epoch {epoch + 1} with Val Accuracy: {ValidationAccuracy:.2f}% and Test Accuracy: {TestingAccuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
