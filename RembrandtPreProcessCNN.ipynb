{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f751c9",
   "metadata": {},
   "source": [
    "REMBRANDT Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "#Resizes, normalizes, and converts images to tensors.\n",
    "TransformImagesREM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "#Finds all DICOM files from REMBRANDT filepath, setting file count limits and shuffling as well.\n",
    "def Collect_Dicoms(path, max_files=None, random_shuffle=True):\n",
    "    DCMFiles = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(path)\n",
    "        for file in files if file.endswith('.dcm')]\n",
    "    if random_shuffle:\n",
    "        random.shuffle(DCMFiles)\n",
    "    return DCMFiles[:max_files] if max_files else DCMFiles\n",
    "\n",
    "#Converts DICOM files to tensors and sets patient IDs.\n",
    "def Convert_Dicoms(filepath):\n",
    "    DCM = pydicom.dcmread(filepath)\n",
    "    ConvertDCM = Image.fromarray(DCM.pixel_array).convert(\"RGB\")\n",
    "    TensorImage = TransformImagesREM(ConvertDCM)\n",
    "    PathID = str(DCM.PatientID).strip()\n",
    "    return TensorImage, PathID\n",
    "\n",
    "#Sets batch sizes and the number of batches to download at a time, then process batches while also accounting for processing errors.\n",
    "def Process_Batches(path, output_path, batch_size=1000, max_batches=10, random_shuffle=True):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    BatchLimit = batch_size * max_batches if max_batches else None\n",
    "    DicomPaths = Collect_Dicoms(path, max_files=BatchLimit, random_shuffle=random_shuffle)\n",
    "    Total, TotalErrors = 0, 0\n",
    "#Append batches to FinalTensors and FinalIDs, converting each image in the batch and checking for errors.\n",
    "    for BatchIndex, i in enumerate(range(0, len(DicomPaths), batch_size), start=1):\n",
    "        BatchPaths = DicomPaths[i:i+batch_size]\n",
    "        FinalTensors = []\n",
    "        FinalIDs = []\n",
    "        print(f\"Processing batch {BatchIndex} ({len(BatchPaths)} files)\")\n",
    "        for path in BatchPaths:\n",
    "            try:\n",
    "                TensorImage, PathID = Convert_Dicoms(path)\n",
    "                FinalTensors.append(TensorImage)\n",
    "                FinalIDs.append(PathID)\n",
    "            except Exception as e:\n",
    "                TotalErrors += 1\n",
    "                with open(\"error_log.txt\", \"a\", encoding=\"utf-8\") as w:\n",
    "                    w.write(f\"{path} - {str(e)}\\n\")\n",
    "#Save the batch tensors to the matching patient IDs.\n",
    "        if FinalTensors:\n",
    "            torch.save(torch.stack(FinalTensors), os.path.join(output_path, f\"batch_{BatchIndex}.pt\"))\n",
    "            torch.save(FinalIDs, os.path.join(output_path, f\"batch_{BatchIndex}_ids.pt\"))\n",
    "            Total += len(FinalTensors)\n",
    "    print(f\"Done. Saved {Total} tensors in {BatchIndex} batches. Total Errors: {TotalErrors}\")\n",
    "    \n",
    "#Provide dataset paths and run preprocessing.\n",
    "REMDirectory = r\"C:\\Users\\hgood\\OneDrive\\REMBRANDT\"\n",
    "ProcessedTensorDir = r\"C:\\Users\\hgood\\OneDrive\\Processed_REMBRANDT\"\n",
    "Process_Batches(REMDirectory, ProcessedTensorDir, batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
