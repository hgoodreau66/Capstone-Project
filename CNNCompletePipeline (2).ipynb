{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0307def5",
   "metadata": {},
   "source": [
    "REMBRANDT Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b575f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 (1000 files)\n",
      "Processing batch 2 (1000 files)\n",
      "Processing batch 3 (1000 files)\n",
      "Processing batch 4 (1000 files)\n",
      "Processing batch 5 (1000 files)\n",
      "Processing batch 6 (1000 files)\n",
      "Processing batch 7 (1000 files)\n",
      "Processing batch 8 (1000 files)\n",
      "Processing batch 9 (1000 files)\n",
      "Processing batch 10 (1000 files)\n",
      "Done. Saved 10000 tensors in 10 batches. Total Errors: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "#Resizes, normalizes, and converts images to tensors.\n",
    "TransformImagesREM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "#Finds all DICOM files from REMBRANDT filepath, setting file count limits and shuffling as well.\n",
    "def Collect_Dicoms(path, max_files=None, random_shuffle=True):\n",
    "    DCMFiles = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(path)\n",
    "        for file in files if file.endswith('.dcm')]\n",
    "    if random_shuffle:\n",
    "        random.shuffle(DCMFiles)\n",
    "    return DCMFiles[:max_files] if max_files else DCMFiles\n",
    "\n",
    "#Converts DICOM files to tensors and sets patient IDs.\n",
    "def Convert_Dicoms(filepath):\n",
    "    DCM = pydicom.dcmread(filepath)\n",
    "    ConvertDCM = Image.fromarray(DCM.pixel_array).convert(\"RGB\")\n",
    "    TensorImage = TransformImagesREM(ConvertDCM)\n",
    "    PathID = str(DCM.PatientID).strip()\n",
    "    return TensorImage, PathID\n",
    "\n",
    "#Sets batch sizes and the number of batches to download at a time, then process batches while also accounting for processing errors.\n",
    "def Process_Batches(path, output_path, batch_size=1000, max_batches=10, random_shuffle=True):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    BatchLimit = batch_size * max_batches if max_batches else None\n",
    "    DicomPaths = Collect_Dicoms(path, max_files=BatchLimit, random_shuffle=random_shuffle)\n",
    "    Total, TotalErrors = 0, 0\n",
    "#Append batches to FinalTensors and FinalIDs, converting each image in the batch and checking for errors.\n",
    "    for BatchIndex, i in enumerate(range(0, len(DicomPaths), batch_size), start=1):\n",
    "        BatchPaths = DicomPaths[i:i+batch_size]\n",
    "        FinalTensors = []\n",
    "        FinalIDs = []\n",
    "        print(f\"Processing batch {BatchIndex} ({len(BatchPaths)} files)\")\n",
    "        for path in BatchPaths:\n",
    "            try:\n",
    "                TensorImage, PathID = Convert_Dicoms(path)\n",
    "                FinalTensors.append(TensorImage)\n",
    "                FinalIDs.append(PathID)\n",
    "            except Exception as e:\n",
    "                TotalErrors += 1\n",
    "                with open(\"error_log.txt\", \"a\", encoding=\"utf-8\") as w:\n",
    "                    w.write(f\"{path} - {str(e)}\\n\")\n",
    "#Save the batch tensors to the matching patient IDs.\n",
    "        if FinalTensors:\n",
    "            torch.save(torch.stack(FinalTensors), os.path.join(output_path, f\"batch_{BatchIndex}.pt\"))\n",
    "            torch.save(FinalIDs, os.path.join(output_path, f\"batch_{BatchIndex}_ids.pt\"))\n",
    "            Total += len(FinalTensors)\n",
    "    print(f\"Done. Saved {Total} tensors in {BatchIndex} batches. Total Errors: {TotalErrors}\")\n",
    "    \n",
    "#Provide dataset paths and run preprocessing.\n",
    "REMDirectory = r\"C:\\Users\\hgood\\OneDrive\\REMBRANDT\"\n",
    "ProcessedTensorDir = r\"C:\\Users\\hgood\\OneDrive\\Processed_REMBRANDT\"\n",
    "Process_Batches(REMDirectory, ProcessedTensorDir, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6a7d1",
   "metadata": {},
   "source": [
    "Create Custom Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#Creates a custom dataset to load preprocessed Rembrandt images with the proper labels.\n",
    "class REMDataset(Dataset):\n",
    "    def __init__(self, batch_directory, label_file, transform=None):\n",
    "        self.transform = transform\n",
    "        self.all_data = []\n",
    "        LabelData = pd.read_csv(label_file)\n",
    "# Filter out rows where 'Grade' is Na\n",
    "        LabelData = LabelData.dropna(subset=['Grade'])\n",
    "#Convert grades to integers\n",
    "        LabelData['Grade'] = LabelData['Grade'].astype(int)\n",
    "# Build label map that maps SampleIDs to Grade\n",
    "        self.label_map = {\n",
    "            str(row['Sample']).strip(): row['Grade']\n",
    "            for _, row in LabelData.iterrows()\n",
    "        }\n",
    "# Iterate through batch files and their ID lists\n",
    "        for file in os.listdir(batch_directory):\n",
    "            if file.endswith('.pt') and 'ids' not in file:\n",
    "                TensorPath = os.path.join(batch_directory, file)\n",
    "                IDPath = TensorPath.replace(\".pt\", \"_ids.pt\")\n",
    "                if not os.path.exists(IDPath):\n",
    "                    continue\n",
    "                FinalImages = torch.load(TensorPath)  \n",
    "                IDFinal = torch.load(IDPath)       \n",
    "#Pair tensor images with the correct grade labels, only including the image in dataset if a label is found.\n",
    "                for tensor, id in zip(FinalImages, IDFinal):\n",
    "                    IDString = str(id).strip()\n",
    "                    Label = self.label_map.get(IDString, -1)  # -1 if missing\n",
    "                    if Label != -1:\n",
    "                        self.all_data.append((tensor, Label))\n",
    "#Return correct image/label pairs.\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        imgREM, Label = self.all_data[index]\n",
    "        return imgREM, Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506d0ed",
   "metadata": {},
   "source": [
    "Build ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.models.resnet as resnet\n",
    "\n",
    "#Build ResNet-18 model.\n",
    "def build_resnet(num_classes=3):\n",
    "    Weights = resnet.ResNet18_Weights.DEFAULT\n",
    "    CNNModel = models.resnet18(weights = Weights)\n",
    "\n",
    "# Replace final fully connected layer to match specified number of classes.\n",
    "    CNNModel.fc = nn.Linear(CNNModel.fc.in_features, num_classes)\n",
    "    return CNNModel\n",
    "\n",
    "CNNModel = build_resnet(num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f7a40",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training at epoch 24 with Validation Accuracy: 83.20%\n",
      "Epoch [25/34], Train Loss: 0.4583, Train Accuracy: 83.51%, Val Loss: 0.4650, Val Accuracy: 83.70%, Test Loss: 0.4160, Test Accuracy: 85.40%\n",
      "Best model saved at epoch 25 with Val Accuracy: 83.70% and Test Accuracy: 85.40%\n",
      "Epoch [26/34], Train Loss: 0.4639, Train Accuracy: 83.44%, Val Loss: 0.4593, Val Accuracy: 84.10%, Test Loss: 0.4114, Test Accuracy: 86.30%\n",
      "Best model saved at epoch 26 with Val Accuracy: 84.10% and Test Accuracy: 86.30%\n",
      "Epoch [27/34], Train Loss: 0.4628, Train Accuracy: 83.51%, Val Loss: 0.4599, Val Accuracy: 83.80%, Test Loss: 0.4171, Test Accuracy: 85.70%\n",
      "Epoch [28/34], Train Loss: 0.4585, Train Accuracy: 83.89%, Val Loss: 0.4515, Val Accuracy: 84.00%, Test Loss: 0.4128, Test Accuracy: 85.40%\n",
      "Epoch [29/34], Train Loss: 0.4566, Train Accuracy: 83.91%, Val Loss: 0.4532, Val Accuracy: 83.90%, Test Loss: 0.4121, Test Accuracy: 85.70%\n",
      "Epoch [30/34], Train Loss: 0.4442, Train Accuracy: 83.94%, Val Loss: 0.4525, Val Accuracy: 84.10%, Test Loss: 0.4106, Test Accuracy: 85.70%\n",
      "Epoch [31/34], Train Loss: 0.4527, Train Accuracy: 83.69%, Val Loss: 0.4558, Val Accuracy: 84.10%, Test Loss: 0.4097, Test Accuracy: 86.10%\n",
      "Epoch [32/34], Train Loss: 0.4526, Train Accuracy: 83.60%, Val Loss: 0.4531, Val Accuracy: 84.00%, Test Loss: 0.4087, Test Accuracy: 86.00%\n",
      "Epoch [33/34], Train Loss: 0.4477, Train Accuracy: 83.78%, Val Loss: 0.4490, Val Accuracy: 84.70%, Test Loss: 0.4089, Test Accuracy: 86.20%\n",
      "Best model saved at epoch 33 with Val Accuracy: 84.70% and Test Accuracy: 86.20%\n",
      "Epoch [34/34], Train Loss: 0.4520, Train Accuracy: 83.79%, Val Loss: 0.4551, Val Accuracy: 84.10%, Test Loss: 0.4084, Test Accuracy: 86.20%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#Set hyperparameters\n",
    "ImageDir = r\"C:\\Users\\hgood\\OneDrive\\Processed_REMBRANDT\"\n",
    "CSVAcess = r\"C:\\Users\\hgood\\Downloads\\clinical_cleaned_v2.csv\"\n",
    "BatchSize = 32\n",
    "EpochCount = 10\n",
    "LearningRate = 0.001\n",
    "Classes = 3\n",
    "BestModelPathCNN = 'best_model.pth'\n",
    "\n",
    "# Set dataset and class weights \n",
    "datasetREM = REMDataset(ImageDir, CSVAcess, transform=TransformImagesREM)\n",
    "REMlabels = [int(label) for _, label in datasetREM]\n",
    "Weights = compute_class_weight(class_weight='balanced', classes=np.unique(REMlabels), y=REMlabels)\n",
    "TensorWeights = torch.tensor(Weights, dtype=torch.float)\n",
    "\n",
    "# Split dataset into train/validation/testing\n",
    "TrainSplit = int(0.8 * len(datasetREM))\n",
    "ValSplit = int(0.1 * len(datasetREM))\n",
    "TestSplit = len(datasetREM) - TrainSplit - ValSplit\n",
    "TrainData, ValData, TestData = random_split(datasetREM, [TrainSplit, ValSplit, TestSplit])\n",
    "#Create data loaders three different ways.\n",
    "TrainingLoader = DataLoader(TrainData, batch_size=BatchSize, shuffle=True)\n",
    "ValidationLoader = DataLoader(ValData, batch_size=BatchSize, shuffle=False)\n",
    "TestingLoader = DataLoader(TestData, batch_size=BatchSize, shuffle=False)\n",
    "\n",
    "# Create model, loss, and optimizer, utilizing an Adam optimizer and learning rate scheduler as well.\n",
    "TorchDevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CNNModel = build_resnet(num_classes=Classes).to(TorchDevice)\n",
    "EntropyREM = nn.CrossEntropyLoss(weight=TensorWeights.to(TorchDevice))\n",
    "OptimizerREM = optim.Adam(CNNModel.parameters(), lr=LearningRate)\n",
    "SchedulerREM = optim.lr_scheduler.StepLR(OptimizerREM, step_size=5, gamma=0.1)\n",
    "\n",
    "# Resume training from checkpoint unless we start training from scratch\n",
    "start_epoch = 0\n",
    "best_val_accuracy = 0.0\n",
    "if os.path.exists(BestModelPathCNN):\n",
    "    checkpoint = torch.load(BestModelPathCNN)\n",
    "    CNNModel.load_state_dict(checkpoint['model_state_dict'])\n",
    "    OptimizerREM.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_accuracy = checkpoint['val_accuracy']\n",
    "    print(f\"Resuming training at epoch {start_epoch} with Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "\n",
    "TotalEpochs = start_epoch + EpochCount\n",
    "\n",
    "# Function to calculate accuracy and loss metrics.\n",
    "def evaluate_accuracy_metrics(loader):\n",
    "    CNNModel.eval()\n",
    "    CorrectPredictions = 0\n",
    "    TotalPredictions = 0\n",
    "    TotalLoss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, REMlabels in loader:\n",
    "            inputs, REMlabels = inputs.to(TorchDevice), REMlabels.to(TorchDevice)\n",
    "            outputs = CNNModel(inputs)\n",
    "            loss = EntropyREM(outputs, REMlabels)\n",
    "            TotalLoss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            CorrectPredictions += (predicted == REMlabels).sum().item()\n",
    "            TotalPredictions += REMlabels.size(0)\n",
    "    return TotalLoss / len(loader), 100 * CorrectPredictions/ TotalPredictions\n",
    "\n",
    "# Create the training loop.\n",
    "for epoch in range(start_epoch, TotalEpochs):\n",
    "    CNNModel.train()\n",
    "    TotalLoss = 0.0\n",
    "    CorrectPredictions = 0\n",
    "    TotalPredictions = 0\n",
    "# Reset gradients, pass outputs forward, calculate total loss, and utilize optimizer.\n",
    "    for inputs, REMlabels in TrainingLoader:\n",
    "        inputs, REMlabels = inputs.to(TorchDevice), REMlabels.to(TorchDevice)\n",
    "        OptimizerREM.zero_grad()\n",
    "        outputs = CNNModel(inputs)\n",
    "        loss = EntropyREM(outputs, REMlabels)\n",
    "        loss.backward()\n",
    "        OptimizerREM.step()\n",
    "        TotalLoss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        CorrectPredictions += (predicted == REMlabels).sum().item()\n",
    "        TotalPredictions += REMlabels.size(0)\n",
    "#Evaluate the model on both validation and test sets.\n",
    "    AvgTrainingLoss = TotalLoss/len(TrainingLoader)\n",
    "    TrainingAccuracy = 100 * CorrectPredictions/TotalPredictions\n",
    "    ValidationLoss, ValidationAccuracy = evaluate_accuracy_metrics(ValidationLoader)\n",
    "    TestingLoss, TestingAccuracy = evaluate_accuracy_metrics(TestingLoader)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{TotalEpochs}], Train Loss: {AvgTrainingLoss:.4f}, Train Accuracy: {TrainingAccuracy:.2f}%, \"\n",
    "          f\"Val Loss: {ValidationLoss:.4f}, Val Accuracy: {ValidationAccuracy:.2f}%, \"\n",
    "          f\"Test Loss: {TestingLoss:.4f}, Test Accuracy: {TestingAccuracy:.2f}%\")\n",
    "\n",
    "    SchedulerREM.step()\n",
    "# Save the latest checkpoint.\n",
    "    torch.save({\n",
    "        'model_state_dict': CNNModel.state_dict(),\n",
    "        'optimizer_state_dict': OptimizerREM.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, 'model_checkpoint.pth')\n",
    "\n",
    "# Save best model if the validation accuracy improves.\n",
    "    if ValidationAccuracy > best_val_accuracy:\n",
    "        best_val_accuracy = ValidationAccuracy\n",
    "        torch.save({\n",
    "            'model_state_dict': CNNModel.state_dict(),\n",
    "            'optimizer_state_dict': OptimizerREM.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'val_accuracy': ValidationAccuracy,\n",
    "            'test_accuracy': TestingAccuracy\n",
    "        }, BestModelPathCNN)\n",
    "        print(f\"Best model saved at epoch {epoch + 1} with Val Accuracy: {ValidationAccuracy:.2f}% and Test Accuracy: {TestingAccuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c374f",
   "metadata": {},
   "source": [
    "Assign Grades to BTP Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d03a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to C:\\Users\\hgood\\OneDrive\\Documents\\Brain-Tumor-ProgressionCNNAssignments.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set paths and reutilize previous transformations.\n",
    "BTPDataset = r\"C:\\Brain-Tumor-Progression\"\n",
    "BTPGrades = r\"C:\\Users\\hgood\\OneDrive\\Documents\\Brain-Tumor-ProgressionCNNAssignments.csv\"\n",
    "BestModelPath = \"best_model.pth\"\n",
    "transformREM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "#Load ResNet model.\n",
    "Device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BuildResnet = build_resnet(num_classes=3)\n",
    "BuildResnet.load_state_dict(torch.load(BestModelPath, map_location=Device)['model_state_dict'])\n",
    "BuildResnet.to(Device)\n",
    "BuildResnet.eval()\n",
    "\n",
    "#Function that predicts most common gades from each DICOM file in a folder.\n",
    "def Folder_Grades(scan_folder):\n",
    "    GradePrediction = []\n",
    "    for root, _, files in os.walk(scan_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.dcm'):\n",
    "                try:\n",
    "# Convert DICOMs to RGB PIL images, add batch dimensions, get the class index and predict grades.\n",
    "                    DCMBTP = pydicom.dcmread(os.path.join(root, file))\n",
    "                    ConvertDCMBTP = Image.fromarray(DCMBTP.pixel_array).convert(\"RGB\")\n",
    "                    TensorImageBTP = transformREM(ConvertDCMBTP).unsqueeze(0).to(Device)\n",
    "                    with torch.no_grad():\n",
    "                        ArgMax = torch.argmax(BuildResnet(TensorImageBTP), dim=1).item()\n",
    "                    GradePrediction.append(ArgMax)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "    return Counter(GradePrediction).most_common(1)[0][0] if GradePrediction else None\n",
    "\n",
    "#Collect predictions after iterating through the entire dataset.\n",
    "FolderPredictions = []\n",
    "for patientid in os.listdir(BTPDataset):\n",
    "    Patient = os.path.join(BTPDataset, patientid)\n",
    "    if not os.path.isdir(Patient): continue\n",
    "    for folderdate in os.listdir(Patient):\n",
    "        Dates = os.path.join(Patient, folderdate)\n",
    "        if not os.path.isdir(Dates): continue\n",
    "#Only process files if they are in T1post or FLAIR folders.\n",
    "        for checkfolders in os.listdir(Dates):\n",
    "            if not any(tag in checkfolders for tag in [\"T1post\", \"FLAIR\"]):\n",
    "                continue\n",
    "            Scans = os.path.join(Dates, checkfolders)\n",
    "            FinalGrades = Folder_Grades(Scans)\n",
    "            if FinalGrades is not None:\n",
    "                FolderPredictions.append({\n",
    "                    \"PatientID\": patientid,\n",
    "                    \"ScanDateFolder\": folderdate,\n",
    "                    \"PredictedGrade\": FinalGrades\n",
    "                })\n",
    "                break  \n",
    "#Output predictions to a CSV file.\n",
    "pd.DataFrame(FolderPredictions).to_csv(BTPGrades, index=False)\n",
    "print(f\"Predictions saved to {BTPGrades}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
